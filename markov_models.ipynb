{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q00dTe2dLR_Z"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IAT-ComputationalCreativity-Spring2025/Week3-Rule-Based-Systems/blob/main/markov_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6N76Slm2LR_c"
      },
      "source": [
        "# Markov Models Text Generation\n",
        "\n",
        "This notebook introduces Markov chains for text generation. We'll build a simple\n",
        "text generator that learns patterns from input text and generates new text with\n",
        "similar statistical properties."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "a7aI_XIbLR_d"
      },
      "outputs": [],
      "source": [
        "# First, let's import our required libraries\n",
        "from collections import defaultdict\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctvjo5H5LR_e"
      },
      "source": [
        "## Building the Markov Chain\n",
        "\n",
        "A Markov chain represents sequences of states where the probability of each state\n",
        "depends only on the previous state(s). In our case, each state will be a sequence\n",
        "of words, and we'll predict the next word based on this sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "cMmfX4rPLR_e"
      },
      "outputs": [],
      "source": [
        "def build_markov_chain(text, order=2):\n",
        "    \"\"\"\n",
        "    Build a Markov chain from input text.\n",
        "\n",
        "    Args:\n",
        "        text (str): Input text to learn from\n",
        "        order (int): Number of words to use as state (context)\n",
        "\n",
        "    Returns:\n",
        "        dict: Mapping from state tuples to lists of possible next words\n",
        "    \"\"\"\n",
        "    chain = defaultdict(list)\n",
        "    words = text.split()\n",
        "\n",
        "    for i in range(len(words) - order):\n",
        "        # Create state tuple from current words\n",
        "        state = tuple(words[i:i+order])\n",
        "        # Get the next word\n",
        "        next_word = words[i+order]\n",
        "        # Add to chain\n",
        "        chain[state].append(next_word)\n",
        "\n",
        "    return chain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLCO4hH1LR_e"
      },
      "source": [
        "## Generating Text\n",
        "\n",
        "Now we'll use our Markov chain to generate new text. We'll randomly select from\n",
        "the possible next words at each step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1m9-6FOuLR_f"
      },
      "outputs": [],
      "source": [
        "def generate_text(chain, num_words=50):\n",
        "    \"\"\"\n",
        "    Generate new text using the Markov chain.\n",
        "\n",
        "    Args:\n",
        "        chain (dict): Markov chain mapping states to possible next words\n",
        "        order (int): Length of state tuples\n",
        "        num_words (int): Number of words to generate\n",
        "\n",
        "    Returns:\n",
        "        str: Generated text\n",
        "    \"\"\"\n",
        "    # Start with a random state from the chain\n",
        "    words = list(random.choice(list(chain.keys())))\n",
        "    order = len(list(chain.keys())[0])\n",
        "\n",
        "    for _ in range(num_words - order):\n",
        "        state = tuple(words[-order:])\n",
        "        if state in chain:\n",
        "            next_word = random.choice(chain[state])\n",
        "            words.append(next_word)\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    return ' '.join(words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOoYAUR1LR_f"
      },
      "source": [
        "## Part 3: Basic Example\n",
        "\n",
        "Let's try our text generator with a simple example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLYFhO7ZLR_f",
        "outputId": "fc5baf2a-f857-42e2-e7dd-8f47e8218917"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The quick -> ['brown']\n",
            "quick brown -> ['fox', 'dog', 'dog']\n",
            "brown fox -> ['jumps']\n",
            "fox jumps -> ['over']\n",
            "jumps over -> ['the', 'the']\n",
            "over the -> ['lazy', 'lazy']\n",
            "the lazy -> ['dog.', 'fox.']\n",
            "lazy dog. -> ['A']\n",
            "dog. A -> ['quick']\n",
            "A quick -> ['brown']\n",
            "brown dog -> ['jumps', 'watches.']\n",
            "dog jumps -> ['over']\n",
            "lazy fox. -> ['The']\n",
            "fox. The -> ['lazy']\n",
            "The lazy -> ['fox']\n",
            "lazy fox -> ['sleeps']\n",
            "fox sleeps -> ['while']\n",
            "sleeps while -> ['the']\n",
            "while the -> ['quick']\n",
            "the quick -> ['brown']\n"
          ]
        }
      ],
      "source": [
        "# Sample text\n",
        "sample_text = \"\"\"\n",
        "The quick brown fox jumps over the lazy dog.\n",
        "A quick brown dog jumps over the lazy fox.\n",
        "The lazy fox sleeps while the quick brown dog watches.\n",
        "\"\"\"\n",
        "\n",
        "# Build the chain\n",
        "chain = build_markov_chain(sample_text)\n",
        "\n",
        "# Examine the chain\n",
        "for state, words in chain.items():\n",
        "    print(f\"{' '.join(state)} -> {words}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxN9-kc_LR_g",
        "outputId": "9a8352d0-7396-4f1f-fb2f-ebb884f8b3f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated text:\n",
            "brown fox jumps over the lazy dog. A quick brown dog jumps over the lazy fox. The lazy fox sleeps while the quick brown dog jumps over the lazy fox. The lazy fox sleeps while the quick brown dog jumps over the lazy dog. A quick brown fox jumps over\n"
          ]
        }
      ],
      "source": [
        "# Generate some text\n",
        "print(\"Generated text:\")\n",
        "print(generate_text(chain))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_icQJcrLR_g"
      },
      "source": [
        "## Student Tasks\n",
        "\n",
        "1. Basic Implementation:\n",
        "   - Try changing the order parameter in build_markov_chain\n",
        "   - What happens with order=1 vs order=3?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1ASLuaGLR_g",
        "outputId": "35b650b9-081c-46fb-e3ba-c4fb7f8cf532"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Order 1:\n",
            "the quick brown dog jumps over the lazy fox jumps over the quick brown fox jumps over the quick brown fox jumps over the quick brown dog watches.\n",
            "\n",
            "Order 3:\n",
            "brown fox jumps over the lazy fox. The lazy fox sleeps while the quick brown dog jumps over the lazy fox. The lazy fox sleeps while the quick brown dog jumps over the lazy fox. The lazy fox sleeps while the quick brown dog watches.\n"
          ]
        }
      ],
      "source": [
        "# Task 1: Experiment with different orders\n",
        "print(\"\\nOrder 1:\")\n",
        "chain1 = build_markov_chain(sample_text, order=1)\n",
        "print(generate_text(chain1))\n",
        "\n",
        "print(\"\\nOrder 3:\")\n",
        "chain3 = build_markov_chain(sample_text, order=3)\n",
        "print(generate_text(chain3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmcYkjgFLR_g"
      },
      "source": [
        "2. Use Your Own Text:\n",
        "   Below, try using a different text source. You could use:\n",
        "   - Song lyrics\n",
        "   - Book excerpts\n",
        "   - Movie quotes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCj-7zurLR_h",
        "outputId": "d8cc49b2-1593-4c34-feb4-42179392e0a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Order 1:\n",
            "point that night of bubbling like the same size and redder. Also it out without a gigantic tom-cat purring. This grew to the tunnel. Wisps of the party, and the same size and past him coming to throb in the tunnel, an opening of much the bravest thing he ever\n",
            "\n",
            "Order 3:\n",
            "no doubt about it. It was a red light steadily getting redder and redder. Also it was now undoubtedly hot in the tunnel. Wisps of vapour floated up and past him and he began to sweat. A sound, too, began to throb in his ears, a sort of bubbling like\n"
          ]
        }
      ],
      "source": [
        "# Task 2: Add your own text here\n",
        "your_text = \"\"\"\n",
        "Then the hobbit slipped on his ring, and warned by the echoes to take more than hobbit's care to make no sound, he crept noiselessly down, down, down into the dark.\n",
        "He was trembling with fear, but his little face was set and grim. Already he was a very different hobbit from the one that had run out without a pocket-handkerchief from Bag-End long ago.\n",
        "He had not had a pocket-handkerchief for ages. He loosened his dagger in its sheath, tightened his belt, and went on. “Now you are in for it at last, Bilbo Baggins,” he said to himself.\n",
        "“You went and put your foot right in it that night of the party, and now you have got to pull it out and pay for it! Dear me, what a fool I was and am!” said the least Tookish part of him.\n",
        "“I have absolutely no use for dragon-guarded treasures, and the whole lot could stay here for ever, if only I could wake up and find this beastly tunnel was my own front-hall at home!”\n",
        "He did not wake up of course, but went still on and on, till all sign of the door behind had faded away. He was altogether alone. Soon he thought it was beginning to feel warm.\n",
        "“Is that a kind of a glow I seem to see coming right ahead down there?” he thought.  It was. As he went forward it grew and grew, till there was no doubt about it.\n",
        "It was a red light steadily getting redder and redder. Also it was now undoubtedly hot in the tunnel. Wisps of vapour floated up and past him and he began to sweat.\n",
        "A sound, too, began to throb in his ears, a sort of bubbling like the noise of a large pot galloping on the fire, mixed with a rumble as of a gigantic tom-cat purring.\n",
        "This grew to the unmistakable gurgling noise of some vast animal snoring in its sleep down there in the red glow in front of him.   It was at this point that Bilbo stopped.\n",
        "Going on from there was the bravest thing he ever did. The tremendous things that happened afterward were as nothing compared to it.\n",
        "He fought the real battle in the tunnel alone, before he ever saw the vast danger that lay in wait.\n",
        "At any rate after a short halt go on he did; and you can picture him coming to the end of the tunnel, an opening of much the same size and shape as the door above.\n",
        "Through it peeps the hobbit's little head. Before him lies the great bottommost cellar or dungeon-hall of the ancient dwarves right at the Mountain's root.\n",
        "It is almost dark so that its vastness can only be dimly guessed, but rising from the near side of the rocky floor there is a great glow. The glow of Smaug!\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "print(\"\\nOrder 1:\")\n",
        "mychain1 = build_markov_chain(your_text, order=1)\n",
        "print(generate_text(mychain1))\n",
        "\n",
        "print(\"\\nOrder 3:\")\n",
        "mychain3 = build_markov_chain(your_text, order=3)\n",
        "print(generate_text(mychain3))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieBFqtxXLR_h"
      },
      "source": [
        "3. Advanced Implementation:\n",
        "   Add temperature-based sampling to control randomness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_cfQDU6LR_h",
        "outputId": "7cce30c1-2304-425f-c5c1-73e2f1dd8bda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "default:\n",
            "me, what a very different hobbit slipped on his ears, a red light steadily getting redder and am!” said the tunnel. Wisps of him. It was trembling with a kind of vapour floated up of Smaug!\n",
            "\n",
            "temp 2 order 3:\n",
            "Mountain's root. It is a pocket-handkerchief for ever, if only I seem to pull it peeps the great bottommost cellar or dungeon-hall of the hobbit from Bag-End long ago. He\n",
            "\n",
            "temp 2 order 10:\n",
            "real battle in its vastness can only be dimly guessed, but his dagger in its sleep down there was the same size and redder. Also it was trembling with fear,\n",
            "\n",
            "temp 4 order 1:\n",
            "sweat. A sound, too, began to the near side of some vast danger that Bilbo stopped. Going on his dagger in its sheath, tightened his belt, and past him and\n"
          ]
        }
      ],
      "source": [
        "def generate_text_with_temperature(chain, temperature, num_words=30, order=1):\n",
        "    \"\"\"\n",
        "    Generate text with temperature-based sampling.\n",
        "    Lower temperature = more conservative/predictable\n",
        "    Higher temperature = more random/creative\n",
        "\n",
        "    Args:\n",
        "        chain (dict): Markov chain\n",
        "        temperature (float): Controls randomness (0.1 to 2.0 recommended)\n",
        "        order (int): Length of state tuples\n",
        "        num_words (int): Number of words to generate\n",
        "    \"\"\"\n",
        "    words = list(random.choice(list(chain.keys())))\n",
        "    order = len(list(chain.keys())[0])\n",
        "\n",
        "    for _ in range(num_words - order):\n",
        "        state = tuple(words[-order:])\n",
        "        if state in chain:\n",
        "            # Count frequencies of next words\n",
        "            next_words = chain[state]\n",
        "            word_counts = defaultdict(int)\n",
        "            for word in next_words:\n",
        "                word_counts[word] += 1\n",
        "\n",
        "            # Apply temperature\n",
        "            weights = [count ** (1.0 / temperature) for count in word_counts.values()]\n",
        "            total = sum(weights)\n",
        "            weights = [w/total for w in weights]\n",
        "\n",
        "            # Choose next word based on weighted probabilities\n",
        "            next_word = random.choices(list(word_counts.keys()), weights=weights)[0]\n",
        "            words.append(next_word)\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    return ' '.join(words)\n",
        "\n",
        "# Try different temperatures\n",
        "# print(\"\\nLow temperature (more predictable):\")\n",
        "# print(generate_text_with_temperature(chain, temperature=0.3))\n",
        "\n",
        "# print(\"\\nHigh temperature (more random):\")\n",
        "# print(generate_text_with_temperature(chain, temperature=2.0))\n",
        "\n",
        "# print(\"\\nLow temperature (more predictable):\")\n",
        "# print(generate_text_with_temperature(mychain1, temperature=0.3))\n",
        "\n",
        "# print(\"\\nHigh temperature (more random):\")\n",
        "# print(generate_text_with_temperature(mychain1, temperature=2.0))\n",
        "\n",
        "# print(\"\\nLow temperature (more predictable):\")\n",
        "# print(generate_text_with_temperature(mychain3, temperature=0.3))\n",
        "\n",
        "chain4 = build_markov_chain(your_text, order = 1)\n",
        "\n",
        "print(\"\\ndefault:\")\n",
        "print(generate_text(chain4))\n",
        "print(\"\\ntemp 2 order 3:\")\n",
        "print(generate_text_with_temperature(chain4, temperature=2.0, order =3.0))\n",
        "print(\"\\ntemp 2 order 10:\")\n",
        "print(generate_text_with_temperature(chain4, temperature=2.0, order =10.0))\n",
        "print(\"\\ntemp 4 order 1:\")\n",
        "print(generate_text_with_temperature(chain4, temperature=4.0, order =1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWWp1tGgLR_h"
      },
      "source": [
        "## Challenge Tasks:\n",
        "\n",
        "1. Implement a function to analyze the Markov chain:\n",
        "   - Count the number of unique states\n",
        "   - Find the most common transitions\n",
        "   - Calculate the average number of possible next words for each state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEkv51YCLR_h",
        "outputId": "1e0a3994-5038-4c6c-f01b-a4c3e2b112c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Chain Analysis:\n",
            "Number of unique states: 20\n",
            "Average transitions per state: 1.30\n",
            "\n",
            "Most common transitions:\n",
            "The quick -> brown (count: 1)\n",
            "quick brown -> dog (count: 2)\n",
            "brown fox -> jumps (count: 1)\n",
            "fox jumps -> over (count: 1)\n",
            "jumps over -> the (count: 2)\n",
            "Number of unique states: 273\n",
            "Average transitions per state: 1.77\n",
            "\n",
            "Most common transitions:\n",
            "Then -> the (count: 1)\n",
            "the -> door (count: 2)\n",
            "hobbit -> slipped (count: 1)\n",
            "slipped -> on (count: 1)\n",
            "on -> his (count: 1)\n",
            "Number of unique states: 480\n",
            "Average transitions per state: 1.00\n",
            "\n",
            "Most common transitions:\n",
            "Then the hobbit -> slipped (count: 1)\n",
            "the hobbit slipped -> on (count: 1)\n",
            "hobbit slipped on -> his (count: 1)\n",
            "slipped on his -> ring, (count: 1)\n",
            "on his ring, -> and (count: 1)\n"
          ]
        }
      ],
      "source": [
        "def analyze_chain(chain):\n",
        "    \"\"\"\n",
        "    Analyze properties of the Markov chain.\n",
        "\n",
        "    Args:\n",
        "        chain (dict): Markov chain to analyze\n",
        "    \"\"\"\n",
        "    num_states = len(chain)\n",
        "    total_transitions = sum(len(next_words) for next_words in chain.values())\n",
        "    avg_transitions = total_transitions / num_states if num_states > 0 else 0\n",
        "\n",
        "    # Find most common next word for each state\n",
        "    most_common = {}\n",
        "    for state, next_words in chain.items():\n",
        "        word_counts = defaultdict(int)\n",
        "        for word in next_words:\n",
        "            word_counts[word] += 1\n",
        "        most_common[state] = max(word_counts.items(), key=lambda x: x[1])\n",
        "\n",
        "    print(f\"Number of unique states: {num_states}\")\n",
        "    print(f\"Average transitions per state: {avg_transitions:.2f}\")\n",
        "    print(\"\\nMost common transitions:\")\n",
        "    for state, (word, count) in list(most_common.items())[:5]:  # Show top 5\n",
        "        print(f\"{' '.join(state)} -> {word} (count: {count})\")\n",
        "\n",
        "# Analyze our chain\n",
        "print(\"\\nChain Analysis:\")\n",
        "analyze_chain(chain)\n",
        "\n",
        "analyze_chain(mychain1)\n",
        "\n",
        "\n",
        "analyze_chain(mychain3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_l0l_Y6LR_h"
      },
      "source": [
        "## Further Exploration:\n",
        "\n",
        "Other ideas to try:\n",
        "1. Modify the code to preserve punctuation\n",
        "2. Add start-of-sentence and end-of-sentence tokens\n",
        "3. Implement bi-directional generation\n",
        "4. Create a chain that works with characters instead of words\n",
        "5. Add input validation and error handling"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "iat460",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}